from functools import partial

import numpy as np
import torch

from damri.model.agent_net import resnet
from damri.model.spottune_unet_layerwise import UNet2D
from dpipe.torch.functional import weighted_cross_entropy_with_logits
from dpipe.predict import add_extract_dims, divisible_shape
from damri.batch_iter import slicewise
from damri.spottune import train_step_spottune, inference_step_spottune
from damri.metric import compute_metrics_probably_with_ids_spottune
from dpipe.train import Checkpoints
from dpipe.train.policy import Schedule


# loss
criterion = weighted_cross_entropy_with_logits

# model
n_filters = 16
architecture_main = UNet2D(n_chans_in=n_chans_in, n_chans_out=n_chans_out, n_filters_init=n_filters)
architecture_policy = resnet(num_class=66)

x_patch_size = y_patch_size = np.array([256, 256])
batch_size = 20

# optimizer
batches_per_epoch = 100
n_epochs = 60

lr_init_main = 1e-3
lr_main = Schedule(initial=lr_init_main, epoch2value_multiplier={45: 0.1, })

lr_init_policy = 0.01
lr_policy = Schedule(initial=lr_init_policy, epoch2value_multiplier={45: 0.1, })

optimizer_main = torch.optim.SGD(
    architecture_main.parameters(),
    lr=lr_init_main,
    momentum=0.9,
    nesterov=True,
    weight_decay=0
)

optimizer_policy = torch.optim.SGD(
    architecture_policy.parameters(),
    lr=lr_init_policy,
    momentum=0.9,
    nesterov=True,
    weight_decay=0.001
)

# spottune kwargs
use_gumbel_inference = False
temperature = 0.1
k_reg = 0
reg_mode = 'l1'
with_source = False
k_reg_source = None
alpha_l2sp = None

train_kwargs = dict(lr_main=lr_main, lr_policy=lr_policy, k_reg=k_reg, k_reg_source=k_reg_source, reg_mode=reg_mode,
                    architecture_main=architecture_main, architecture_policy=architecture_policy,
                    temperature=temperature, with_source=with_source, optimizer_main=optimizer_main,
                    optimizer_policy=optimizer_policy, criterion=criterion, alpha_l2sp=alpha_l2sp)

# Checkpoints
checkpoints = Checkpoints(checkpoints_path, {
    **{k: v for k, v in train_kwargs.items() if isinstance(v, Policy)},
    'model_main.pth': architecture_main, 'model_policy.pth': architecture_policy,
    'optimizer_main.pth': optimizer_main, 'optimizer_policy.pth': optimizer_policy
})

# training
train_model = train(
    train_step=train_step_spottune,
    batch_iter=batch_iter,
    n_epochs=n_epochs,
    logger=logger,
    checkpoints=checkpoints,
    validate=validate_step,
    **train_kwargs
)

# validation
validate_step = partial(compute_metrics_probably_with_ids_spottune, predict=val_predict,
                        load_x=load_x, load_y=load_y, ids=val_ids, metrics=val_metrics,
                        architecture_main=architecture_main)

# predict
@slicewise  # 3D -> 2D iteratively
@add_extract_dims(2)  # 2D -> (4D -> predict -> 4D) -> 2D
@divisible_shape(divisor=[8] * 2, padding_values=np.min)  # since the unet arch. input should be divided by 8
def predict(image):
    return inference_step_spottune(image, architecture_main=architecture_main, architecture_policy=architecture_policy,
                                   activation=torch.sigmoid, temperature=temperature, use_gumbel=use_gumbel_inference)

